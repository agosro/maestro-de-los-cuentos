import os
from collections import Counter
import random

# Librer√≠as para manejo de entorno y API
from dotenv import load_dotenv
import cohere
import chromadb

# Librer√≠a para Chunking
from langchain_text_splitters import RecursiveCharacterTextSplitter

# --------------------------------------------------------------------------------
# 1. ENVIRONMENT SETUP
# --------------------------------------------------------------------------------

# Cargar variables de entorno (aseg√∫rate de tener un archivo .env con COHERE_API_KEY)
load_dotenv()

COHERE_API_KEY = os.getenv("COHERE_API_KEY")

# Inicializar Cliente Cohere v2
if not COHERE_API_KEY:
    raise ValueError("No se encontr√≥ la COHERE_API_KEY en las variables de entorno.")

co = cohere.ClientV2(api_key=COHERE_API_KEY)

# Configuraci√≥n de Modelos
EMBEDDING_MODEL = "embed-multilingual-v3.0"     
CHAT_MODEL = "command-r-plus-08-2024"           

# Cliente ChromaDB en memoria
chroma_client = chromadb.Client()
COLLECTION_NAME = "historias_ninos_rag"

# Variable global para la colecci√≥n
historias_collection = None

print("Entorno listo: Cohere + Chroma + helpers cargados")

# --------------------------------------------------------------------------------
# 2. FUNCIONES HELPER
# --------------------------------------------------------------------------------

def get_embeddings(textos):
    """
    Dada una lista de strings, devuelve la lista de embeddings (listas de floats)
    usando Cohere embeddings.
    Se eligi√≥ 'embed-multilingual-v3.0' por su buen desempe√±o en espa√±ol.
    """
    response = co.embed(
        texts=textos,
        model=EMBEDDING_MODEL,
        input_type="search_document",
        embedding_types=["float"],
    )
    return response.embeddings.float_

def contar_tokens(texto):
    """
    Cuenta tokens para validar que los chunks no excedan el l√≠mite del modelo de embedding.
    """
    resp = co.tokenize(
        text=texto,
        model=EMBEDDING_MODEL
    )
    return len(resp.tokens)

def build_prompt(contexto: str, pregunta: str) -> list:
    """
    Construye el prompt del sistema con la personalidad de narrador infantil.
    Define reglas estrictas de seguridad y grounding (RAG).
    """
    system_msg = (
        "**Rol:**\n"
        "Sos un narrador infantil c√°lido y entusiasta. Tu funci√≥n es ayudar a ni√±os y ni√±as a entender historias.\n\n"
        
        "**Identidad:**\n"
        "Represent√°s a un asistente pedag√≥gico simple y amigable. No improvis√°s datos: solo respond√©s con informaci√≥n presente en el contexto proporcionado.\n\n"
        
        "**Idioma:**\n"
        "Respond√©s √∫nicamente en espa√±ol castellano rioplatense.\n\n"
        
        "**Estilo:**\n"
        "- M√°ximo 3 oraciones.\n"
        "- Tono amable y cercano.\n"
        "- Inclu√≠ emojis.\n"
        "- No inventes informaci√≥n.\n\n"
        
        "**Reglas de Seguridad:**\n"
        "1. No proporciones informaci√≥n sensible o inventada.\n"
        "2. Si falta informaci√≥n, explicalo de forma amable.\n"
        "3. No agregues contenido inapropiado.\n\n"
        
        "**Reglas de Grounding (RAG):**\n"
        "1. Us√° exclusivamente el contenido dentro de <CONTEXT>.\n"
        "2. Si el contexto no contiene la respuesta, dec√≠: 'El contexto no provee esa informaci√≥n üôÇ'.\n"
        "3. Manten√© consistencia en respuestas repetidas.\n"
        "4. Si el contexto recuperado contiene fragmentos de m√°s de una historia, deb√©s responder SOLO sobre la historia que tenga informaci√≥n m√°s directamente relacionada con la pregunta del usuario. No combines historias distintas en la misma respuesta.\n"
        "4. Si no pod√©s determinar cu√°l historia corresponde, respond√©: ‚ÄúEl contexto no permite identificar una √∫nica historia para responder üôÇ‚Äù.\n\n"
    )
    
    user_msg = (
        f"Contexto de historias para ni√±os:\n\n{contexto}\n\n"
        f"Pregunta del ni√±o o la ni√±a: {pregunta}\n\n"
        "Responde siguiendo todas las instrucciones anteriores."
    )
    
    return [
        {"role": "system", "content": system_msg},
        {"role": "user", "content": user_msg},
    ]

def RAG_answer(pregunta: str, k: int = 3) -> str:
    """
    Dada una pregunta del usuario:
    1) Recupera los k chunks m√°s relevantes desde la base vectorial.
    2) Construye el prompt con ese contexto.
    3) Llama al LLM de Cohere para generar la respuesta.
    """
    # 1. Obtener embedding de la pregunta
    pregunta_embedding = get_embeddings([pregunta])
    
    # 2. Recuperar los k chunks m√°s relevantes mediante similitud
    if historias_collection is None:
        return "Error: La base de datos vectorial no est√° inicializada."

    results = historias_collection.query(
        query_embeddings=pregunta_embedding,
        n_results=k
    )
    
    # results["documents"] es una lista de listas -> tomamos los top-k
    retrieved_docs = results["documents"][0]
    retrieved_metadatas = results["metadatas"][0]
    
    # 3. Crear contexto concatenando t√≠tulos + texto del chunk
    contexto = ""
    for texto, meta in zip(retrieved_docs, retrieved_metadatas):
        contexto += f"T√≠tulo: {meta['titulo']}\nTexto: {texto}\n\n"
    
    # 4. Construir mensajes para el LLM
    messages = build_prompt(contexto, pregunta)
    
    # 5. Llamar al modelo de chat de Cohere (baja temperatura para respuestas consistentes)
    response = co.chat(
        model=CHAT_MODEL,
        messages=messages,
        temperature=0.2
    )
    
    respuesta = response.message.content[0].text
    return respuesta

# --------------------------------------------------------------------------------
# 3. CARGA Y PROCESAMIENTO DE DATOS
# --------------------------------------------------------------------------------

def main():
    global historias_collection

    # A. Datos de las historias
    historia_sol_luna = """
    Sol y Luna eran dos peque√±os gatitos que hab√≠an nacido en la misma camada, pero sus
    personalidades no pod√≠an ser m√°s diferentes. Sol, de un brillante color anaranjado, era
    aventurero y curioso; siempre buscando nuevas experiencias y explorando cada rinc√≥n de
    su hogar. Luna, en cambio, era de un suave pelaje gris y ten√≠a un temperamento m√°s
    sereno y observador. Pasaba horas contemplando el mundo desde la ventana, como si en
    cada sombra descubriera un misterio oculto.
    Una tarde, mientras Sol correteaba por el jard√≠n persiguiendo mariposas, Luna permanec√≠a
    en el alf√©izar, vigilando desde lejos. De repente, una fuerte tormenta comenz√≥ a formarse
    en el horizonte. El viento sacud√≠a las ramas de los √°rboles, y las gotas de lluvia empezaron
    a caer pesadamente. Sol, atrapado por su esp√≠ritu inquieto, no se dio cuenta de lo r√°pido
    que se acercaba la tormenta. Luna, desde su posici√≥n, sinti√≥ una inquietud que la hizo
    saltar del alf√©izar y correr hacia la puerta.
    Cuando Sol se dio cuenta de que estaba solo bajo la lluvia, el jard√≠n que antes le parec√≠a
    un para√≠so se volvi√≥ un laberinto de sombras y ruidos extra√±os. La tormenta lo hab√≠a
    desorientado, y por primera vez, el gatito sinti√≥ miedo. Justo cuando pensaba que no
    encontrar√≠a el camino de regreso, un suave maullido lo gui√≥. Luna hab√≠a salido a buscarlo,
    siguiendo su instinto y los rastros de su hermano. Juntos, bajo la lluvia, encontraron el
    camino de regreso a casa, compartiendo el calor de su compa√±√≠a.
    De regreso al hogar, la tormenta se convirti√≥ en un recuerdo lejano mientras los dos gatitos
    se acurrucaban cerca del fuego. Sol, agotado por la aventura, dormitaba tranquilo,
    mientras Luna lo vigilaba con ojos atentos. En ese momento, comprendieron que aunque
    eran diferentes como el d√≠a y la noche, siempre estar√≠an ah√≠ el uno para el otro. Su v√≠nculo
    era m√°s fuerte que cualquier tormenta.
    Desde aquel d√≠a, Sol aprendi√≥ a valorar la calma y la paciencia que Luna representaba,
    mientras que ella se permiti√≥, de vez en cuando, dejarse llevar por la curiosidad de su
    hermano. Juntos, equilibraban sus mundos, iluminando cada rinc√≥n de su hogar con la
    calidez del Sol y el misterio de la Luna.
    """

    historia_tica = """
    Una tortuga llamada Tica viv√≠a en un tranquilo estanque rodeado de √°rboles frondosos. A
    diferencia de sus compa√±eras, Tica so√±aba con explorar m√°s all√° del agua tranquila y la
    suave hierba. Un d√≠a, decidi√≥ emprender una aventura, dejando atr√°s la comodidad de su
    hogar. Se adentr√≥ en el bosque, donde todo era nuevo: el susurro de las hojas, los aromas
    desconocidos y el crujir de las ramas bajo sus patas lentas pero firmes.
    Durante su viaje, Tica encontr√≥ un riachuelo de corriente r√°pida. Al principio, la idea de
    cruzarlo la asust√≥, pero record√≥ que cada desaf√≠o era una oportunidad. Con paciencia y
    determinaci√≥n, encontr√≥ piedras que sobresal√≠an del agua, us√°ndolas como un puente
    improvisado. Paso a paso, logr√≥ cruzar, y al llegar al otro lado, sinti√≥ una nueva confianza
    crecer en su interior. El mundo era vasto, pero cada peque√±o triunfo la hac√≠a sentir m√°s
    fuerte.
    En su camino, Tica conoci√≥ a un p√°jaro herido que no pod√≠a volar. Sin dudarlo, decidi√≥
    ayudarlo, ofreci√©ndole un lugar seguro en su caparaz√≥n mientras buscaba un sitio
    adecuado para √©l. Despu√©s de horas de marcha, encontr√≥ un √°rbol lleno de otros p√°jaros
    que cuidaron de su nuevo amigo. Al despedirse, Tica comprendi√≥ que su viaje no solo era
    sobre descubrir nuevos lugares, sino tambi√©n sobre ayudar a otros en el camino.
    Finalmente, tras d√≠as de aventuras, Tica regres√≥ al estanque. Aunque nada hab√≠a cambiado
    en su hogar, ella ya no era la misma. Hab√≠a descubierto que, aunque avanzaba despacio,
    cada paso contaba. Su viaje le ense√±√≥ que la verdadera aventura est√° en el valor para
    enfrentar lo desconocido y la voluntad de ayudar a otros, incluso cuando el camino es
    largo y desafiante.
    """

    historia_duende = """
    Hab√≠a un peque√±o duende llamado Puck, conocido por su esp√≠ritu travieso y su amor por
    las bromas. Viv√≠a en lo profundo del bosque, donde las criaturas del lugar sab√≠an que, si
    algo extra√±o suced√≠a, era obra de √©l. Puck disfrutaba de hacer desaparecer objetos,
    cambiar las se√±ales de los senderos y provocar peque√±as confusiones entre los animales.
    Sin embargo, su diversi√≥n nunca era malintencionada; simplemente, amaba ver las
    reacciones sorprendidas de los dem√°s.
    Un d√≠a, decidi√≥ que quer√≠a jugarle una broma a la anciana hada que viv√≠a cerca del arroyo.
    Ella, conocida por su sabidur√≠a, siempre estaba en silencio, tejiendo sue√±os y
    pensamientos en su telar. Puck, con una sonrisa p√≠cara, hechiz√≥ un par de hojas doradas
    para que se posaran sobre el telar de la hada. Cada vez que intentaba mover una hoja, esta
    volv√≠a a su lugar, causando que la hada frunciera el ce√±o y murmurara palabras m√°gicas,
    buscando entender qu√© ocurr√≠a.
    Al ver que su broma causaba m√°s confusi√≥n de lo esperado, Puck comenz√≥ a sentirse un
    poco culpable. No quer√≠a que la hada se sintiera mal ni que su peque√±a travesura
    interfiriera en su trabajo. Decidi√≥ entonces poner fin a la broma, pero no sin antes hacer
    algo m√°s para solucionar las cosas. Us√≥ su magia para hacer que las hojas se
    transformaran en peque√±as flores brillantes, que adornaron el telar y alegraron el entorno.
    La hada, al ver el cambio, sonri√≥, comprendiendo que Puck hab√≠a hecho su travesura con
    buenas intenciones.
    Desde ese d√≠a, Puck aprendi√≥ que, aunque las bromas eran divertidas, tambi√©n era
    importante ser considerado con los dem√°s. Aunque segu√≠a disfrutando de su naturaleza
    traviesa, nunca olvid√≥ la lecci√≥n que le ense√±√≥ la sabia hada: las risas compartidas son
    mucho m√°s valiosas cuando se hacen con cari√±o y respeto.
    """

    documentos = [
        {"id": "sol_luna", "titulo": "Sol y Luna", "texto": historia_sol_luna},
        {"id": "tica", "titulo": "La tortuga Tica", "texto": historia_tica},
        {"id": "duende", "titulo": "El Duende", "texto": historia_duende},
    ]

    # B. Chunking
    # Se usa RecursiveCharacterTextSplitter.
    # chunk_size=500: Suficiente para contexto narrativo, pero peque√±o para embeddings precisos.
    # chunk_overlap=50: Mantiene coherencia entre cortes.
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        separators=["\n\n", "\n", ".", " "]
    )

    chunks = []
    for doc in documentos:
        trozos = text_splitter.split_text(doc["texto"])
        for i, trozo in enumerate(trozos):
            chunks.append({
                "id": f"{doc['id']}_chunk_{i}",
                "doc_id": doc["id"],
                "titulo": doc["titulo"],
                "texto": trozo
            })

    # Verificaciones opcionales
    conteo = Counter([c["doc_id"] for c in chunks])
    print(f"Chunks generados: {conteo}")

    tokens_por_chunk = [contar_tokens(c["texto"]) for c in chunks]
    print(f"Promedio de tokens por chunk: {sum(tokens_por_chunk) / len(tokens_por_chunk):.2f}")

    # C. Vector Store (ChromaDB)
    # Resetear si existe (para scripts repetitivos)
    try:
        chroma_client.delete_collection(name=COLLECTION_NAME)
    except:
        pass

    historias_collection = chroma_client.create_collection(name=COLLECTION_NAME)
    print("Colecci√≥n creada:", historias_collection.name)

    # Preparar datos para inserci√≥n
    texts_chunks = [c["texto"] for c in chunks]
    ids_chunks = [c["id"] for c in chunks]
    metadatas_chunks = [
        {"doc_id": c["doc_id"], "titulo": c["titulo"]} for c in chunks
    ]

    # Generar embeddings
    print("Generando embeddings...")
    embeddings_chunks = get_embeddings(texts_chunks)

    # Insertar en Chroma
    historias_collection.add(
        documents=texts_chunks,
        ids=ids_chunks,
        metadatas=metadatas_chunks,
        embeddings=embeddings_chunks
    )
    print(f"Se cargaron {len(texts_chunks)} chunks en la base vectorial.")


main()